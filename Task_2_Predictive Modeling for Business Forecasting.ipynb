{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa68e13f-2a33-4d00-a91e-75be946ffe16",
   "metadata": {},
   "source": [
    "# I'm Creating a Predictive Machine Learning Model to see which variables between \"x1\"... and \"x81\" are best used to predict Financial Distress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c46d2d7-452c-4fdf-9bd7-244c59b9dde0",
   "metadata": {},
   "source": [
    "# This is a streamlined process for creating a predictive model using Machine Learning \n",
    " 1. Data Preparation\n",
    "Import Libraries: Load necessary libraries.\n",
    "Load the Dataset: Read the CSV file into a DataFrame.\n",
    "Explore the Dataset: Display rows, summary statistics, and structure.\n",
    "Prepare Features and Target Variables: Separate features and target variable.\n",
    "Create a Subset of Data: Extract selected key features.\n",
    "2. Data Preprocessing\n",
    "Additional Imports: Import functions for modeling and preprocessing.\n",
    "Split Data: Divide data into training and testing sets.\n",
    "Scale Features: Standardize features for improved performance.\n",
    "Generate Polynomial Features: Create squared and interaction features.\n",
    "Create Lag Features: Generate lagged versions of key features.\n",
    "Scale Polynomial Features: Standardize polynomial features.\n",
    "Combine Final Features: Merge and drop missing values.\n",
    "Scale Final Features: Standardize the final feature set.\n",
    "3. Model Training\n",
    "Train the Model: Fit the RandomForestRegressor using training data.\n",
    "4. Feature Importance Analysis\n",
    "Determine Feature Importances: Extract and sort feature importance.\n",
    "Visualize Feature Importances: Create bar plots of top features.\n",
    "Enhanced Visualization: Use color palettes for clarity.\n",
    "5. Correlation and Insights\n",
    "Correlation Analysis: Compute correlation matrix for features.\n",
    "Visualize Top Factors: Plot top correlated features.\n",
    "Enhanced Visualization: Improve readability with distinct colors.\n",
    "6. Final Preparation\n",
    "Prepare Final Target Variable: Extract target variable for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9b148-7615-407a-a481-b97cf30ebece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 \n",
    "# Load essential libraries for data manipulation, numerical operations, and visualization.\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c4771c-fdaa-42b8-9a74-608c6940dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 \n",
    "# Read the CSV file containing the dataset into a DataFrame for analysis.\n",
    "\n",
    "df = pd.read_csv(\"Financial Distress Edited.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4fade-c45e-431b-9caa-2efc6be9c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "# Display the first few rows, summary statistics, and information about the datasetâ€™s structure and data types\n",
    "df.head()\n",
    "df.describe()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d67af-d887-4623-b816-d2a64810bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# Import specific functions from sklearn for building models, splitting data, and preprocessing.\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee73ee2-63ad-417a-b68b-15e219cb509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 \n",
    "# Compute the correlation matrix to identify relationships between features and the target variable (financial distress).\n",
    "correlation_matrix = df.corr()\n",
    "target_correlation = correlation_matrix[\"Financial Distress\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e5cb3-1d3b-4bf0-8013-959a4648a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "# Create bar plots to visualize the top features that correlate with financial distress, aiding in feature selection.\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=target_correlation[1:11], y=target_correlation.index[1:11])\n",
    "plt.title(\"Top 10 Factors Linked to Financial Distress\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6a267-4934-451c-98a1-ebf7ab41ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 \n",
    "# This code is the same as the one above, except for the fact that this code represents each variable in the bar plot with a different color/\n",
    "# In simpler terms, the code uses distinct colors in the bar plots for improved readability and aesthetics.\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Generate a color palette with 10 different colors\n",
    "colors = sns.color_palette(\"husl\", 10)\n",
    "sns.barplot(x=target_correlation[1:11], y=target_correlation.index[1:11], palette=colors)\n",
    "plt.title(\"Top 10 Factors Linked to Financial Distress\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937382dc-0ee6-4f7e-8dc6-df2777dece3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 \n",
    "# Separate the dataset into features (independent variables) and the target variable (financial distress).\n",
    "X = df.drop(columns=[\"Financial Distress\", \"Company\", \"Time\"])\n",
    "y = df[\"Financial Distress\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc801c86-5392-4bb8-8fb3-32b0ca2c4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 \n",
    "# Divide the data into training and testing subsets to evaluate model performance on unseen data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051683b-f046-4f9f-b156-70a1d68055c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 \n",
    "# Standardize the features to ensure they have a mean of 0 and a standard deviation of 1, improving model performance.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7135ae-1838-49c8-a843-7230679f94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11\n",
    "# Initialize and fit the RandomForestRegressor model using the scaled training data.\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2189f0-c93a-42ea-a318-f2186000b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12\n",
    "# Extract and sort the importance of each feature in predicting the target variable.\n",
    "feature_importances = rf_model.feature_importances_\n",
    "sorted_indices = feature_importances.argsort()[::-1]\n",
    "top_features = X.columns[sorted_indices[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f2d969-6a46-47f4-8a82-d24ac25adb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13\n",
    "# Create bar plots to display the importance of the top features identified by the model\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=feature_importances[sorted_indices[:10]], y=top_features)\n",
    "plt.title(\"RandomForest's Top 10 Feature Importances\")\n",
    "plt.show()\n",
    "\n",
    "top_features, target_correlation[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86ed46-e7bf-447e-8b42-28dab3e2c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14\n",
    "# Use a distinct color palette for the feature importance plots to enhance clarity.\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Generate a color palette with 10 distinct colors\n",
    "colors = sns.color_palette(\"husl\", 10)\n",
    "sns.barplot(x=feature_importances[sorted_indices[:10]], y=top_features, palette=colors)\n",
    "plt.title(\"RandomForest's Top 10 Feature Importances\")\n",
    "plt.show()\n",
    "\n",
    "top_features, target_correlation[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c95c5-1122-489b-ab94-66ab039419c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15\n",
    "# Prepare to create polynomial and interaction features to capture more complex relationships.\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b156c-61aa-4318-ad35-8cd31553453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16\n",
    "# Define which features will be used for polynomial feature engineering.\n",
    "key_features = [\"x81\", \"x48\", \"x25\", \"x10\", \"x9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c7138-8f69-4cc6-a220-c22b61a13ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17\n",
    "# Extract the selected key features from the original dataset for further processing.\n",
    "selected_data = df[key_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331b7e9-a50d-434a-971b-ead914d6c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18\n",
    "# Create new features that represent squared terms and interactions of the original features.\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2455b-7fca-496d-8eb4-ebe71b864064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19 \n",
    "# Retrieve the names of the newly created polynomial features for easier reference.\n",
    "poly_feature_names = poly.get_feature_names_out(key_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51e4b7-5b8d-4af7-bd4e-5f08220f42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 \n",
    "# Convert the polynomial features into a DataFrame for further analysis.\n",
    "poly_df = pd.DataFrame(poly_features, columns=poly_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab0bd3-22f1-4305-8162-d45874105181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21\n",
    "# Generate lagged versions of the key features to help the model capture time-based patterns.\n",
    "for feature in key_features:\n",
    "    selected_data[f\"(feature)_lag1\"] = selected_data[feature].shift(1)\n",
    "    selected_data[f\"(feature)_lag2\"] = selected_data[feature].shift(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d827dc-86af-452d-a28d-e11ecbb4770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22\n",
    "# Standardize the polynomial features to maintain consistency with the original feature set.\n",
    "poly_df_scaled = pd.DataFrame(scaler.fit_transform(poly_df), columns=poly_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ce936-d7ca-4510-9b55-6f0e619ee22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23\n",
    "# Merge the scaled polynomial features with the original features, dropping any missing values.\n",
    "final_features = pd.concat([poly_df_scaled, selected_data], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b4133-806b-41d5-88bb-290100802eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24\n",
    "# Further standardize the combined final features for use in modeling.\n",
    "final_features_scaled = pd.DataFrame(scaler.fit_transform(final_features), columns=final_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719327a2-8033-4135-a62e-79fa942d8e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26\n",
    "# Extract the target variable corresponding to the final features for model training and evaluation.\n",
    "final_target= df[\"Financial Distress\"][final_features.index]\n",
    "\n",
    "final_features_scaled.head(), final_target.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
